{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import pickle\n",
    "import nltk #a python natual language toolkit. Has pruning resources\n",
    "import pandas as pd\n",
    "import operator\n",
    "import unicodedata\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from collections import Counter as counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the charlotte business list that has each business's census tract\n",
    "char_bizs = pickle.load(open('charlotte_bizs_census.p','rb'))\n",
    "\n",
    "#Add the zipcode as an element of each business\n",
    "for business in char_bizs:\n",
    "    zip_code = business['full_address'][-5:]\n",
    "    business['zip_code'] = zip_code\n",
    "char_bizs.sort(key=operator.itemgetter('review_count'),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the census tracts for our samples\n",
    "gent_cts = [38.05,37,36,41,7,8,9,14,18.02]\n",
    "ungent_cts = [38.06, 38.07,38.08,38.02,32.01,39.02,39.02,40,43.05,43.03,43.04,43.02,42,45,44,54.01,54.03,54.04,51,50,49,48,46,45,42,52,53.06,23,18.01,17.01,21,19.19,17.02,16.07,16.09,19.12,16.06,16.05,16.03,16.08,15.04,15.09,15.10,13,53.01,52,53.06,53.05,53.06,58.07,54.07,54.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revs_g2015 = [] #2015 reviews of businesses in gentrified areas\n",
    "revs_g2010 = [] #2010 reviews of businesses in gentrified areas\n",
    "revs_u2015 = [] #2015 reviews of businesses in ungentrified areas\n",
    "revs_u2010 = [] #2010 reviews of businesses in ungentrified areas\n",
    "\n",
    "revs_gen_all = [] #all reviews of businesses in gentrified areas, 2010-2015\n",
    "revs_ungen_all = [] #all reviews of businesses in ungentrified areas, 2010-2015\n",
    "\n",
    "for biz in char_bizs:\n",
    "    reviews = biz['reviews']\n",
    "    ct_num = biz['ct_num'] # census track number\n",
    "    categoryList = biz['categories']\n",
    "    \n",
    "    # Use only businesses that serve food\n",
    "    if set(categoryList).intersection(['Food','Restaurants','Hotels']):\n",
    "    \n",
    "        for rev in reviews:\n",
    "            year = rev['date'].split('-')[0]\n",
    "            year = int(year)\n",
    "            revtext = rev['text']\n",
    "\n",
    "            # Add review to the appropriate category \n",
    "            if (ct_num in gent_cts) and (year == 2015):\n",
    "                revs_g2015.append(revtext)\n",
    "            if (ct_num in gent_cts) and (year == 2010):\n",
    "                revs_g2010.append(revtext)\n",
    "            if (ct_num in ungent_cts) and (year == 2015):\n",
    "                revs_u2015.append(revtext)\n",
    "            if (ct_num in ungent_cts) and (year == 2010):\n",
    "                revs_u2010.append(revtext)\n",
    "                \n",
    "            if (ct_num in gent_cts) and (2010 <= year <= 2015):\n",
    "                revs_gen_all.append(revtext)\n",
    "            if (ct_num in ungent_cts) and (2010 <= year <= 2015):\n",
    "                revs_ungen_all.append(revtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-f85bff3e456c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-f85bff3e456c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print len(revs_g2010), len(revs_g2015), len(revs_u2010),len(revs_u2015)\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print len(revs_g2010), len(revs_g2015), len(revs_u2010),len(revs_u2015)\n",
    "print len(revs_gen_all), len(revs_ungen_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_passes = 20\n",
    "use_bigrams = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_corpus(reviewList):\n",
    "    '''A function to produce an lda topic model, \n",
    "    given a list of Yelp review texts\n",
    "    '''\n",
    "\n",
    "    # I would make these inputs instead of global variable, but I don't know\n",
    "    # how to make that work with 'map', below\n",
    "    \n",
    "    #Check whether or not they're defined yet:\n",
    "    if (use_bigrams not in locals()) or (num_passes not in locals()):\n",
    "        print 'Define these in your environment first'\n",
    "\n",
    "   \n",
    "    print 'Use Bigrams:'\n",
    "    print use_bigrams\n",
    "    print 'Number of Passes:'\n",
    "    print num_passes\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # create English stop words list\n",
    "    en_stop = get_stop_words('en')\n",
    "\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    \n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "\n",
    "    en_stop.append(u's')\n",
    "    en_stop.append(u't')\n",
    "   \n",
    "    # loop through document list\n",
    "    for i in reviewList:\n",
    "    \n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "         # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens)\n",
    "    \n",
    "    texts_final = []\n",
    "    \n",
    "    if use_bigrams:\n",
    "        for i in texts:\n",
    "            text_temp = []\n",
    "            for j in range(len(i) - 1):\n",
    "                #print (i[j])\n",
    "                text_temp.append(i[j] + '_' + i[j+1])\n",
    "            texts_final.append(text_temp)\n",
    "    else:\n",
    "        texts_final = texts\n",
    "    \n",
    "    # turn our tokenized documents into a id <-> term dictionary\n",
    "    dictionary = corpora.Dictionary(texts_final)\n",
    "\n",
    "    # convert tokenized documents into a document-term matrix\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts_final]\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # create English stop words list\n",
    "    en_stop = get_stop_words('en')\n",
    "\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    \n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "\n",
    "    en_stop.append(u's')\n",
    "    en_stop.append(u't')\n",
    "   \n",
    "    # loop through document list\n",
    "    for i in revs_gen_all:#revs_ungen_all\n",
    "    \n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "         # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens)\n",
    "    \n",
    "    texts_final = []\n",
    "    \n",
    "    for i in texts:\n",
    "        for j in range(len(i) - 1):\n",
    "            #print (i[j])\n",
    "            texts_final.append(i[j] + '_' + i[j+1])\n",
    "        #texts_final.append(text_temp)\n",
    "    texts_final = counter(texts_final)\n",
    "   \n",
    "    dictWords = texts_final.most_common()\n",
    "    texts_final = pd.DataFrame(dictWords)\n",
    "    texts_final.to_csv('WordCount_gent.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def char_ldamodel(reviewList):\n",
    "    \n",
    "    corpus = create_corpus(reviewList)\n",
    "\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=num_passes)\n",
    "\n",
    "    return ldamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_topic_model(ldamodel,output_fname='',num_words=10):\n",
    "    ''' For outputting the results of a topic model \n",
    "    into a more human-readable format\n",
    "    '''\n",
    "    \n",
    "    #Format final output\n",
    "    mat = ldamodel.print_topics(num_topics=10, num_words=num_words)\n",
    "    final_output = []\n",
    "    \n",
    "    for i in mat:\n",
    "        topic = i[1]\n",
    "        weights_words = topic.split('+')\n",
    "        words = [w.split('*')[1] for w in weights_words] #Get rid of weights\n",
    "        words = [unicodedata.normalize('NFKD', word).encode('ascii','ignore') for word in words]\n",
    "        final_output.append(words)\n",
    "    \n",
    "    output_frame = pd.DataFrame(final_output)\n",
    "\n",
    "    # If a filename has been specified, save the topic model\n",
    "    if output_fname:\n",
    "        output_frame.to_csv(output_fname,encoding='utf-8')\n",
    "   \n",
    "    return output_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have four topic models to run; let's run them all at once to save time\n",
    "def easy_parallize(f, sequence):\n",
    "\n",
    "    from multiprocessing import Pool\n",
    "    pool = Pool(processes=4) # number of cores(threads?)\n",
    "    \n",
    "    result = pool.map(f, sequence) #a list of all the topic models requested\n",
    "    \n",
    "    # Dispose of any empty results (needed only if #processes != len(sequence)?)\n",
    "    cleaned = [x for x in result if not x is None] \n",
    "    cleaned = np.asarray(cleaned)\n",
    "   \n",
    "    # not optimal but safe\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# produce the four topic models, one for each list of reviews\n",
    "#%time results = easy_parallize(char_ldamodel,[revs_g2015,revs_g2010,revs_u2015,revs_u2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 207 ms, sys: 101 ms, total: 308 ms\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "#Let's try not using bigrams\n",
    "#%time monoresults = easy_parallize(char_ldamodel,[revs_g2015,revs_g2010,revs_u2015,revs_u2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.35 s, sys: 2.45 s, total: 9.8 s\n",
      "Wall time: 2h 1min 38s\n"
     ]
    }
   ],
   "source": [
    "#Let's try using many passes, and bigrams\n",
    "# mp stands for 'many passes'\n",
    "#%time bigram_mp = easy_parallize(char_ldamodel,[revs_g2015,revs_g2010,revs_u2015,revs_u2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.49 s, sys: 2.08 s, total: 8.57 s\n",
      "Wall time: 2h 27min 18s\n"
     ]
    }
   ],
   "source": [
    "#Let's try using many passes, and unigrams\n",
    "#%time unigram_mp = easy_parallize(char_ldamodel,[revs_g2015,revs_g2010,revs_u2015,revs_u2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's using many passes, and unigrams\n",
    "#%time unigram_mp = easy_parallize(char_ldamodel,[revs_g2015,revs_g2010,revs_u2015,revs_u2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's generate a topic model for all the 2015 data, and all the 2010 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save or load the topic model results\n",
    "\n",
    "#pickle.dump(results,open('tms_bigrams.p','wb'))\n",
    "#pickle.dump(monoresults,open('tms_monograms.p','wb'))\n",
    "#pickle.dump(bigram_mp,open('tms_bigrams_mp.p','wb'))\n",
    "#pickle.dump(unigram_mp,open('tms_unigrams_mp.p','wb'))\n",
    "\n",
    "bigram_mods = pickle.load(open('tms_bigrams_mp.p','rb'))\n",
    "unigram_mods = pickle.load(open('tms_unigrams_mp.p','rb'))\n",
    "\n",
    "# Save the results\n",
    "\n",
    "mod_g2015 = bigram_mods[0] # unigram topic model for 2015, gentrified-area reviews\n",
    "mod_g2010 = bigram_mods[1]\n",
    "mod_u2015 = bigram_mods[2]\n",
    "mod_u2010 = bigram_mods[3]\n",
    "\n",
    "mod_g2015u = unigram_mods[0] # unigram topic model for 2015, gentrified-area reviews\n",
    "mod_g2010u = unigram_mods[1]\n",
    "mod_u2015u = unigram_mods[2]\n",
    "mod_u2010u = unigram_mods[3]\n",
    "\n",
    "#Output results \n",
    "\n",
    "num_words = 10\n",
    "g2015 = output_topic_model(mod_g2015,'tm_mp_bigram_10w_gent_2015.csv',num_words)\n",
    "g2010 = output_topic_model(mod_g2010,'tm_mp_bigram_10w_gent_2010.csv',num_words)\n",
    "u2015 = output_topic_model(mod_u2015,'tm__mp_bigram_10w_ungent_2015.csv',num_words)\n",
    "u2010 = output_topic_model(mod_u2010,'tm_mp_bigram_10w_ungent_2010.csv',num_words)\n",
    "g2015u = output_topic_model(mod_g2015u,'tm_mp_unigram_10w_gent_2015.csv',num_words)\n",
    "g2010u = output_topic_model(mod_g2010u,'tm_mp_unigram_10w_gent_2010.csv',num_words)\n",
    "u2015u = output_topic_model(mod_u2015u,'tm_mp_unigram_10w_ungent_2015.csv',num_words)\n",
    "u2010u = output_topic_model(mod_u2010u,'tm_mp_unigram_10w_ungent_2010.csv',num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above calls were from when this notebook was used to both make topic models and examine them. There will be some issues with the variable names if you try to run all the cells above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.4 s, sys: 1.5 s, total: 6.9 s\n",
      "Wall time: 2h 45min 45s\n",
      "CPU times: user 5.22 s, sys: 1.3 s, total: 6.51 s\n",
      "Wall time: 2h 42min 22s\n"
     ]
    }
   ],
   "source": [
    "# Create and output both unigram and bigram topic models,\n",
    "# using all the reviews from 2010-2015, \n",
    "# for gentrified an ungentrified regions\n",
    "\n",
    "num_passes = 1000\n",
    "use_bigrams = True\n",
    "%time bigram_all = easy_parallize(char_ldamodel,[revs_gen_all,revs_ungen_all])\n",
    "pickle.dump(bigram_all,open('tms_all_bigrams_mp.p','wb'))\n",
    "#We write out the entire collection of topic models\n",
    "\n",
    "num_passes = 1000\n",
    "use_bigrams = False #passing so-called inputs to functions like this is bad form, but \n",
    "%time unigram_all = easy_parallize(char_ldamodel,[revs_gen_all,revs_ungen_all])\n",
    "pickle.dump(bigram_all,open('tms_all_unigram_mp.p','wb'))\n",
    "\n",
    "mod_gent = bigram_all[0] # bigram topic model for gentrified-area reviews 2010-2015\n",
    "mod_ungent = bigram_all[1] # bigram topic model for gentrified-area reviews 2010-2015\n",
    "g_all = output_topic_model(mod_gent,'tm_all_mp_bigram_10w_gent.csv',num_words)\n",
    "ung_all = output_topic_model(mod_ungent,'tm_all_mp_bigram_10w_ungent.csv',num_words)\n",
    "\n",
    "\n",
    "mod_gent = unigram_all[0] # unigram topic model for gentrified-area reviews 2010-2015\n",
    "mod_ungent = unigram_all[1] # unigram topic model for gentrified-area reviews 2010-2015\n",
    "g_all_u = output_topic_model(mod_gent,'tm_all_mp_unigram_10w_gent.csv',num_words)\n",
    "ung_all_u = output_topic_model(mod_ungent,'tm_all_mp_unigram_10w_ungent.csv',num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print use_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define these in your environment first\n",
      "Define these in your environment first\n",
      "Use Bigrams:\n",
      "Use Bigrams:\n",
      "True\n",
      "True\n",
      "Number of Passes:\n",
      "Number of Passes:\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "bigram_all = easy_parallize(char_ldamodel,[revs_gen_all,revs_ungen_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(bigram_all,open('tms_all_bigrams_mp.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_words = 10\n",
    "mod_gent = bigram_all[0] # bigram topic model for gentrified-area reviews 2010-2015\n",
    "mod_ungent = bigram_all[1] # bigram topic model for gentrified-area reviews 2010-2015\n",
    "g_all = output_topic_model(mod_gent,'tm_all_mp_bigram_10w_gent.csv',num_words)\n",
    "ung_all = output_topic_model(mod_ungent,'tm_all_mp_bigram_10w_ungent.csv',num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4c04dfa02465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mallmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrevs_gen_all\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrevs_ungen_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "allmodel = create_corpus(revs_gen_all + revs_ungen_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = 30\n",
    "allmodel_readable = output_topic_model(mod_gent,'tm_all_GenAndUngen_bigram_10w_gent.csv',num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  food_truck </td>\n",
       "      <td>     pale_ale </td>\n",
       "      <td>      tap_room </td>\n",
       "      <td> dog_friendli </td>\n",
       "      <td>     go_back </td>\n",
       "      <td>     tripl_c </td>\n",
       "      <td>    room_clean </td>\n",
       "      <td>    live_music </td>\n",
       "      <td>       park_lot </td>\n",
       "      <td>     fish_taco </td>\n",
       "      <td>...</td>\n",
       "      <td>      can_wait </td>\n",
       "      <td>      tast_room </td>\n",
       "      <td>     can_find </td>\n",
       "      <td>  outdoor_seat </td>\n",
       "      <td> first_impress </td>\n",
       "      <td>        realli_good </td>\n",
       "      <td>   good_thing </td>\n",
       "      <td>    oliv_garden </td>\n",
       "      <td>    pretti_good </td>\n",
       "      <td>  even_though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>   mac_chees </td>\n",
       "      <td>  grill_chees </td>\n",
       "      <td>  sweet_potato </td>\n",
       "      <td>  hyatt_place </td>\n",
       "      <td> beer_select </td>\n",
       "      <td>  great_food </td>\n",
       "      <td>       go_back </td>\n",
       "      <td>  reason_price </td>\n",
       "      <td>     great_beer </td>\n",
       "      <td>     corn_hole </td>\n",
       "      <td>...</td>\n",
       "      <td>  look_forward </td>\n",
       "      <td>   will_definit </td>\n",
       "      <td>    good_food </td>\n",
       "      <td>     come_back </td>\n",
       "      <td>    will_never </td>\n",
       "      <td>         first_time </td>\n",
       "      <td>     park_lot </td>\n",
       "      <td>  pimento_chees </td>\n",
       "      <td>        can_say </td>\n",
       "      <td>  great_place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> fri_chicken </td>\n",
       "      <td>  realli_good </td>\n",
       "      <td>   picnic_tabl </td>\n",
       "      <td>  pretti_good </td>\n",
       "      <td>   good_food </td>\n",
       "      <td>     go_back </td>\n",
       "      <td>     come_back </td>\n",
       "      <td>     fish_taco </td>\n",
       "      <td>     food_truck </td>\n",
       "      <td>     brown_ale </td>\n",
       "      <td>...</td>\n",
       "      <td>    stay_hyatt </td>\n",
       "      <td>   absolut_love </td>\n",
       "      <td>    long_time </td>\n",
       "      <td>   pretti_much </td>\n",
       "      <td> pretti_decent </td>\n",
       "      <td>         great_food </td>\n",
       "      <td>   call_order </td>\n",
       "      <td>        end_get </td>\n",
       "      <td>   look_forward </td>\n",
       "      <td>  fresh_veggi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>     go_back </td>\n",
       "      <td> crepe_cellar </td>\n",
       "      <td>   pretti_good </td>\n",
       "      <td>      n_chees </td>\n",
       "      <td>       mac_n </td>\n",
       "      <td>   come_back </td>\n",
       "      <td> pimento_chees </td>\n",
       "      <td>     tast_like </td>\n",
       "      <td>      mac_chees </td>\n",
       "      <td>     next_time </td>\n",
       "      <td>...</td>\n",
       "      <td>      wal_mart </td>\n",
       "      <td>     first_time </td>\n",
       "      <td>  great_place </td>\n",
       "      <td>     food_good </td>\n",
       "      <td>   fri_chicken </td>\n",
       "      <td>         goat_chees </td>\n",
       "      <td>     one_best </td>\n",
       "      <td>     will_never </td>\n",
       "      <td>     front_desk </td>\n",
       "      <td>    fish_taco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  front_desk </td>\n",
       "      <td>    free_rang </td>\n",
       "      <td> custom_servic </td>\n",
       "      <td>  fri_chicken </td>\n",
       "      <td>     go_back </td>\n",
       "      <td> beer_select </td>\n",
       "      <td>        5_star </td>\n",
       "      <td>    hyatt_hous </td>\n",
       "      <td> friendli_staff </td>\n",
       "      <td>    craft_beer </td>\n",
       "      <td>...</td>\n",
       "      <td>  larg_portion </td>\n",
       "      <td>      come_back </td>\n",
       "      <td> friend_order </td>\n",
       "      <td>     littl_bit </td>\n",
       "      <td>    never_stay </td>\n",
       "      <td>         coffe_shop </td>\n",
       "      <td>    haven_tri </td>\n",
       "      <td>       can_wait </td>\n",
       "      <td>      grab_beer </td>\n",
       "      <td> salt_caramel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>     go_back </td>\n",
       "      <td>    pull_pork </td>\n",
       "      <td>   fri_chicken </td>\n",
       "      <td>  realli_like </td>\n",
       "      <td> realli_good </td>\n",
       "      <td>   come_back </td>\n",
       "      <td>    first_time </td>\n",
       "      <td> saturday_morn </td>\n",
       "      <td>     watch_game </td>\n",
       "      <td>    drive_thru </td>\n",
       "      <td>...</td>\n",
       "      <td>      didn_see </td>\n",
       "      <td> staff_friendli </td>\n",
       "      <td>   definit_go </td>\n",
       "      <td>     crab_cake </td>\n",
       "      <td>  reason_price </td>\n",
       "      <td>        pretti_good </td>\n",
       "      <td>    next_time </td>\n",
       "      <td>   realli_enjoy </td>\n",
       "      <td> friendli_staff </td>\n",
       "      <td>     give_tri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> great_place </td>\n",
       "      <td>   pork_belli </td>\n",
       "      <td>    food_truck </td>\n",
       "      <td>    fish_taco </td>\n",
       "      <td>    park_lot </td>\n",
       "      <td>     go_back </td>\n",
       "      <td>   realli_good </td>\n",
       "      <td>     come_back </td>\n",
       "      <td>        de_mayo </td>\n",
       "      <td>    first_time </td>\n",
       "      <td>...</td>\n",
       "      <td>   even_though </td>\n",
       "      <td>      just_open </td>\n",
       "      <td>  daili_press </td>\n",
       "      <td>     next_time </td>\n",
       "      <td>     south_end </td>\n",
       "      <td>         coupl_time </td>\n",
       "      <td> outdoor_seat </td>\n",
       "      <td>      good_beer </td>\n",
       "      <td>    coffe_drink </td>\n",
       "      <td>    much_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>   fish_taco </td>\n",
       "      <td>    food_good </td>\n",
       "      <td>       ve_ever </td>\n",
       "      <td>  beer_select </td>\n",
       "      <td>   divin_pie </td>\n",
       "      <td> realli_good </td>\n",
       "      <td>     look_like </td>\n",
       "      <td>   great_place </td>\n",
       "      <td>      come_back </td>\n",
       "      <td>       go_back </td>\n",
       "      <td>...</td>\n",
       "      <td>   small_batch </td>\n",
       "      <td>        pot_pie </td>\n",
       "      <td>   steak_hous </td>\n",
       "      <td>   peopl_watch </td>\n",
       "      <td>  sweet_potato </td>\n",
       "      <td>          next_time </td>\n",
       "      <td>       4_star </td>\n",
       "      <td> saturday_night </td>\n",
       "      <td>      sport_bar </td>\n",
       "      <td>  great_peopl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>     go_back </td>\n",
       "      <td>  fri_chicken </td>\n",
       "      <td>     ice_cream </td>\n",
       "      <td>    come_back </td>\n",
       "      <td>    park_lot </td>\n",
       "      <td>  first_time </td>\n",
       "      <td>     ten_minut </td>\n",
       "      <td>   beer_select </td>\n",
       "      <td>      tast_like </td>\n",
       "      <td>     next_time </td>\n",
       "      <td>...</td>\n",
       "      <td> custom_servic </td>\n",
       "      <td>       give_tri </td>\n",
       "      <td>    bleu_barn </td>\n",
       "      <td>     last_time </td>\n",
       "      <td>     good_food </td>\n",
       "      <td> pleasantli_surpris </td>\n",
       "      <td>     bbq_taco </td>\n",
       "      <td>    barn_bistro </td>\n",
       "      <td>      look_like </td>\n",
       "      <td>    don_think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>  food_truck </td>\n",
       "      <td> truck_friday </td>\n",
       "      <td>     la_quinta </td>\n",
       "      <td>     tasti_yo </td>\n",
       "      <td>  smelli_cat </td>\n",
       "      <td>  great_beer </td>\n",
       "      <td>   great_place </td>\n",
       "      <td>    place_stay </td>\n",
       "      <td>       can_wait </td>\n",
       "      <td> farmer_market </td>\n",
       "      <td>...</td>\n",
       "      <td>    everi_time </td>\n",
       "      <td>   realli_great </td>\n",
       "      <td>      way_get </td>\n",
       "      <td> frozen_yogurt </td>\n",
       "      <td>       ve_ever </td>\n",
       "      <td>            ve_seen </td>\n",
       "      <td>   nice_staff </td>\n",
       "      <td>      can_bring </td>\n",
       "      <td>      allow_dog </td>\n",
       "      <td>  one_favorit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0              1               2              3             4   \\\n",
       "0   food_truck       pale_ale        tap_room   dog_friendli       go_back    \n",
       "1    mac_chees    grill_chees    sweet_potato    hyatt_place   beer_select    \n",
       "2  fri_chicken    realli_good     picnic_tabl    pretti_good     good_food    \n",
       "3      go_back   crepe_cellar     pretti_good        n_chees         mac_n    \n",
       "4   front_desk      free_rang   custom_servic    fri_chicken       go_back    \n",
       "5      go_back      pull_pork     fri_chicken    realli_like   realli_good    \n",
       "6  great_place     pork_belli      food_truck      fish_taco      park_lot    \n",
       "7    fish_taco      food_good         ve_ever    beer_select     divin_pie    \n",
       "8      go_back    fri_chicken       ice_cream      come_back      park_lot    \n",
       "9   food_truck   truck_friday       la_quinta       tasti_yo    smelli_cat    \n",
       "\n",
       "             5               6               7                8   \\\n",
       "0      tripl_c      room_clean      live_music         park_lot    \n",
       "1   great_food         go_back    reason_price       great_beer    \n",
       "2      go_back       come_back       fish_taco       food_truck    \n",
       "3    come_back   pimento_chees       tast_like        mac_chees    \n",
       "4  beer_select          5_star      hyatt_hous   friendli_staff    \n",
       "5    come_back      first_time   saturday_morn       watch_game    \n",
       "6      go_back     realli_good       come_back          de_mayo    \n",
       "7  realli_good       look_like     great_place        come_back    \n",
       "8   first_time       ten_minut     beer_select        tast_like    \n",
       "9   great_beer     great_place      place_stay         can_wait    \n",
       "\n",
       "               9       ...                   20               21  \\\n",
       "0      fish_taco       ...            can_wait        tast_room    \n",
       "1      corn_hole       ...        look_forward     will_definit    \n",
       "2      brown_ale       ...          stay_hyatt     absolut_love    \n",
       "3      next_time       ...            wal_mart       first_time    \n",
       "4     craft_beer       ...        larg_portion        come_back    \n",
       "5     drive_thru       ...            didn_see   staff_friendli    \n",
       "6     first_time       ...         even_though        just_open    \n",
       "7        go_back       ...         small_batch          pot_pie    \n",
       "8      next_time       ...       custom_servic         give_tri    \n",
       "9  farmer_market       ...          everi_time     realli_great    \n",
       "\n",
       "              22              23              24                   25  \\\n",
       "0      can_find    outdoor_seat   first_impress          realli_good    \n",
       "1     good_food       come_back      will_never           first_time    \n",
       "2     long_time     pretti_much   pretti_decent           great_food    \n",
       "3   great_place       food_good     fri_chicken           goat_chees    \n",
       "4  friend_order       littl_bit      never_stay           coffe_shop    \n",
       "5    definit_go       crab_cake    reason_price          pretti_good    \n",
       "6   daili_press       next_time       south_end           coupl_time    \n",
       "7    steak_hous     peopl_watch    sweet_potato            next_time    \n",
       "8     bleu_barn       last_time       good_food   pleasantli_surpris    \n",
       "9       way_get   frozen_yogurt         ve_ever              ve_seen    \n",
       "\n",
       "              26               27               28            29  \n",
       "0    good_thing      oliv_garden      pretti_good    even_though  \n",
       "1      park_lot    pimento_chees          can_say    great_place  \n",
       "2    call_order          end_get     look_forward    fresh_veggi  \n",
       "3      one_best       will_never       front_desk      fish_taco  \n",
       "4     haven_tri         can_wait        grab_beer   salt_caramel  \n",
       "5     next_time     realli_enjoy   friendli_staff       give_tri  \n",
       "6  outdoor_seat        good_beer      coffe_drink      much_food  \n",
       "7        4_star   saturday_night        sport_bar    great_peopl  \n",
       "8      bbq_taco      barn_bistro        look_like      don_think  \n",
       "9    nice_staff        can_bring        allow_dog    one_favorit  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmodel_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
